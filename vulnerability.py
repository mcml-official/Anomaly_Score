import torch
import torch.nn.functional as F
import tqdm
from torch import nn


class Vulnerability:
    def __init__(
        self,
        model: nn.Module,
        eps: float = 8 / 255,
        alpha: float = 2 / 255,
        num_steps: int = 10,
    ):
        super().__init__()
        self.eps = eps
        self.alpha = alpha
        self.num_steps = num_steps
        self.model = model
        self.device = next(self.model.parameters()).device

    def __call__(self, image: torch.Tensor) -> torch.Tensor:
        assert len(image.size()) == 4
        assert not self.model.training
        assert torch.is_grad_enabled

        features = self.model.forward(image).clone().detach()

        adv_image = image.clone().detach().to(self.device)
        adv_image += torch.empty_like(adv_image).uniform_(-1e-6, 1e-6)
        adv_image = torch.clamp(adv_image, min=0, max=1).detach()

        for _ in tqdm.trange(self.num_steps, leave=False):
            adv_image.requires_grad = True

            adv_features = self.model.forward(adv_image)

            loss = F.mse_loss(features, adv_features)

            grad = torch.autograd.grad(
                -loss, adv_image, retain_graph=False, create_graph=False
            )[0]

            adv_image = adv_image + self.alpha * grad.sign()

            delta = torch.clamp(adv_image - image, min=-self.eps, max=self.eps)
            adv_image = torch.clamp(image + delta, min=0, max=1).detach()

        adv_features = self.model.forward(adv_image)

        l2_dist = torch.norm(features - adv_features, p=2, dim=1)

        return l2_dist.detach()
